import json
import pandas as pd
import streamlit as st
import altair as alt
from pathlib import Path
import re
import collections
import itertools

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="å›½ä¼šãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰",
    page_icon="ğŸ›ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSSï¼šç¿»è¨³ãƒ»ç¸¦æ›¸ãåŒ–ã‚’ç„¡åŠ¹åŒ–ï¼ˆSVGãƒ†ã‚­ã‚¹ãƒˆã®ã‚ºãƒ¬é˜²æ­¢ï¼‰+ ãƒ‡ã‚¶ã‚¤ãƒ³æ”¹å–„
st.markdown("""
<style>
/* Google ç¿»è¨³ãŒ SVG ãƒ†ã‚­ã‚¹ãƒˆã‚’ã„ã˜ã‚‰ãªã„ã‚ˆã†ã« */
.notranslate, .vega-embed, .vega-embed * { 
  unicode-bidi: plaintext; 
}
.vega-embed svg text {
  writing-mode: horizontal-tb !important;
  direction: ltr !important;
}
/* ãƒ©ãƒ™ãƒ«ã‚’çœç•¥ã—ãªã„ */
.vega-embed .role-axis-label { text-overflow: clip !important; }

/* ãƒ¡ã‚¤ãƒ³ã‚¿ã‚¤ãƒˆãƒ«ã®ã‚¹ã‚¿ã‚¤ãƒªãƒ³ã‚° */
.main-header {
    background: linear-gradient(90deg, #1f4e79, #2e5c8a);
    color: white;
    padding: 1.5rem;
    border-radius: 10px;
    margin-bottom: 2rem;
    text-align: center;
}

/* ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®ã‚¹ã‚¿ã‚¤ãƒªãƒ³ã‚° */
.metric-container {
    background: #f8f9fa;
    padding: 1rem;
    border-radius: 8px;
    border-left: 4px solid #1f4e79;
}

/* ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ã‚¹ã‚¿ã‚¤ãƒªãƒ³ã‚° */
.sidebar .sidebar-content {
    background: #f8f9fa;
}

/* ã‚¨ãƒ©ãƒ¼ãƒ»è­¦å‘Šãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º */
.stAlert {
    border-radius: 8px;
}
</style>
""", unsafe_allow_html=True)

# Altair ã®è»¸ã‚’æ°´å¹³ã«å›ºå®š & çœç•¥ç„¡ã— + æ—¥æœ¬èªå¯¾å¿œ
alt.themes.register('jp_fix', lambda: {
    "config": {
        "axis": {
            "labelAngle": 0, 
            "labelLimit": 0,  # ãƒ©ãƒ™ãƒ«çœç•¥ã‚’ç„¡åŠ¹åŒ–
            "labelFontSize": 10,
            "titleFontSize": 12,
            "grid": True,
            "tickSize": 5
        },
        "header": {"labelAngle": 0},
        "view": {"strokeWidth": 0},  # æ ç·šã‚’å‰Šé™¤
        "legend": {
            "labelFontSize": 10,
            "titleFontSize": 12
        },
        "title": {
            "fontSize": 14,
            "fontWeight": "bold"
        }
    }
})
alt.themes.enable('jp_fix')

# ãƒ¡ã‚¤ãƒ³ã‚¿ã‚¤ãƒˆãƒ«
st.markdown("""
<div class="main-header">
    <h1>ğŸ›ï¸ å›½ä¼šãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰</h1>
    <p>å›½ä¼šä¼šè­°éŒ²ã‹ã‚‰è­°è«–ã®å…¨ä½“åƒã‚’å¯è¦–åŒ–(ç¾åœ¨25/1/23~8/5ã®ã¿å¯¾å¿œ)</p>
</div>
""", unsafe_allow_html=True)

DATA_DIR = Path(__file__).parent / "data"

@st.cache_data
def load_data():
    """ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿é–¢æ•°"""
    try:
        speeches = pd.read_csv(DATA_DIR / "speeches_sample.csv")
        
        # ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ¬ãƒ³ã‚¸ãƒ³ã‚°
        speeches["date"] = pd.to_datetime(speeches["date"], errors="coerce")
        
        # æ–‡å­—æ•°è¨ˆç®—
        if "speech" in speeches.columns:
            speeches["char_count"] = speeches["speech"].fillna("").astype(str).apply(len)
        else:
            speeches["char_count"] = 0
        
        # æ¬ æåˆ—ã®è£œå®Œ
        required_columns = ["speechURL", "meetingURL", "issueID", "billID", 
                          "speakerGroup", "nameOfHouse", "nameOfMeeting"]
        for col in required_columns:
            if col not in speeches.columns:
                speeches[col] = None
        
        # è¡¨è¨˜çµ±ä¸€
        speeches["party"] = speeches["speakerGroup"].fillna("æ”¿å…šä¸æ˜")
        speeches["house"] = speeches["nameOfHouse"].fillna("é™¢ä¸æ˜")
        speeches["committee"] = speeches["nameOfMeeting"].fillna("å§”å“¡ä¼šä¸æ˜")
        speeches["speaker"] = speeches["speaker"].fillna("ç™ºè¨€è€…ä¸æ˜")
        
        return speeches
    
    except FileNotFoundError:
        st.error("âŒ ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚data/speeches_sample.csv ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        return pd.DataFrame()
    except Exception as e:
        st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return pd.DataFrame()

def extract_keywords(text: str, min_length: int = 2, max_length: int = 6) -> list[str]:
    """ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºé–¢æ•°ï¼ˆæ”¹è‰¯ç‰ˆï¼‰"""
    if not isinstance(text, str) or not text.strip():
        return []
    
    # æ¼¢å­—ã¨ã‚«ã‚¿ã‚«ãƒŠã®æŠ½å‡ºï¼ˆé•·ã•åˆ¶é™ä»˜ãï¼‰
    kanji_pattern = rf'[\u4E00-\u9FFF]{{{min_length},{max_length}}}'
    kata_pattern = rf'[ã‚¡-ãƒ´ãƒ¼]{{{min_length + 1},}}'
    
    kanji_terms = re.findall(kanji_pattern, text)
    kata_terms = re.findall(kata_pattern, text)
    
    # ã‚¹ãƒˆãƒƒãƒ—ãƒ¯ãƒ¼ãƒ‰ï¼ˆæ‹¡å¼µç‰ˆï¼‰
    stop_words = {
        'å§”å“¡ä¼š', 'æœ¬ä¼šè­°', 'æ”¿åºœ', 'ç·ç†', 'å¤§è‡£', 'ç­”å¼', 'è³ªç–‘', 'å ±å‘Š', 'è³‡æ–™', 
        'æ³•å¾‹', 'åˆ¶åº¦', 'ä»Šå›', 'æˆ‘ãŒå›½', 'å›½ä¼š', 'è­°å“¡', 'å…ˆç”Ÿ', 'å§”å“¡', 'è­°è«–',
        'å•é¡Œ', 'èª²é¡Œ', 'å¯¾å¿œ', 'æ¤œè¨', 'å®Ÿæ–½', 'æ¨é€²', 'ç¢ºèª', 'èª¬æ˜', 'è³ªå•'
    }
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    all_terms = kanji_terms + kata_terms
    filtered_terms = [term for term in all_terms if term not in stop_words]
    
    return filtered_terms

def create_heatmap_data(df: pd.DataFrame, top_terms: pd.DataFrame, top_n: int = 15) -> pd.DataFrame:
    """ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ç”¨ãƒ‡ãƒ¼ã‚¿ä½œæˆ"""
    if len(top_terms) == 0:
        return pd.DataFrame()
    
    focus_terms = set(top_terms['term'].head(top_n))
    
    # æ”¿å…šÃ—ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®å‡ºç¾å›æ•°ã‚’é›†è¨ˆ
    heatmap_rows = []
    for party, group in df.groupby('party'):
        party_terms = []
        for speech in group['speech'].fillna(''):
            party_terms.extend([term for term in extract_keywords(speech) if term in focus_terms])
        
        term_counts = collections.Counter(party_terms)
        for term, count in term_counts.items():
            heatmap_rows.append({'party': party, 'term': term, 'count': count})
    
    if not heatmap_rows:
        return pd.DataFrame()
    
    heat_df = pd.DataFrame(heatmap_rows)
    
    # é †åºã‚’æ±ºå®šï¼ˆé »åº¦é †ï¼‰
    term_order = (heat_df.groupby('term')['count'].sum()
                 .sort_values(ascending=False).index.tolist())
    party_order = (heat_df.groupby('party')['count'].sum()
                  .sort_values(ascending=False).index.tolist())
    
    # å…¨çµ„ã¿åˆã‚ã›ã®ãƒãƒˆãƒªãƒƒã‚¯ã‚¹ä½œæˆï¼ˆ0åŸ‹ã‚ï¼‰
    complete_data = []
    for party in party_order:
        for term in term_order:
            count = heat_df[(heat_df['party'] == party) & (heat_df['term'] == term)]['count'].sum()
            complete_data.append({'party': party, 'term': term, 'count': count})
    
    return pd.DataFrame(complete_data)

def truncate_labels(labels: list, max_length: int = 8) -> list:
    """ãƒ©ãƒ™ãƒ«ã‚’æŒ‡å®šæ–‡å­—æ•°ã§åˆ‡ã‚Šè©°ã‚ã‚‹"""
    return [label[:max_length] + "..." if len(label) > max_length else label for label in labels]

def create_readable_chart(data: pd.DataFrame, chart_type: str = "bar", **kwargs) -> alt.Chart:
    """èª­ã¿ã‚„ã™ã„ãƒãƒ£ãƒ¼ãƒˆã‚’ä½œæˆã™ã‚‹ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°"""
    if chart_type == "horizontal_bar":
        return alt.Chart(data).mark_bar().encode(
            x=alt.X(kwargs.get('x'), title=kwargs.get('x_title')),
            y=alt.Y(kwargs.get('y'), 
                   title=kwargs.get('y_title'),
                   sort=kwargs.get('sort', '-x'),
                   axis=alt.Axis(labelLimit=200, labelFontSize=10)),
            color=kwargs.get('color'),
            tooltip=kwargs.get('tooltip')
        ).properties(
            height=kwargs.get('height', 400),
            width=kwargs.get('width', 600)
        )
    
    return alt.Chart(data)

# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
speeches = load_data()

if speeches.empty:
    st.stop()

# =========================
# ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼šãƒ•ã‚£ãƒ«ã‚¿è¨­å®š
# =========================
with st.sidebar:
    st.header("ğŸ” ãƒ•ã‚£ãƒ«ã‚¿è¨­å®š")
    
    # æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿
    if not speeches["date"].isna().all():
        date_min = speeches["date"].min().date()
        date_max = speeches["date"].max().date()
        date_range = st.date_input(
            "ğŸ“… æœŸé–“é¸æŠ", 
            value=(date_min, date_max),
            min_value=date_min,
            max_value=date_max
        )
    else:
        st.warning("æ—¥ä»˜ãƒ‡ãƒ¼ã‚¿ãŒä¸æ­£ã§ã™")
        date_range = None
    
    # é™¢ãƒ•ã‚£ãƒ«ã‚¿
    available_houses = sorted([h for h in speeches["house"].unique() if h and h != "é™¢ä¸æ˜"])
    if available_houses:
        houses = st.multiselect(
            "ğŸ›ï¸ é™¢é¸æŠ", 
            options=available_houses,
            default=available_houses
        )
    else:
        houses = []
    
    # å§”å“¡ä¼šãƒ•ã‚£ãƒ«ã‚¿
    available_committees = sorted([c for c in speeches["committee"].unique() 
                                 if c and c != "å§”å“¡ä¼šä¸æ˜"])[:20]  # è¡¨ç¤ºã‚’20å€‹ã«åˆ¶é™
    if available_committees:
        committees = st.multiselect(
            "ğŸ“‹ å§”å“¡ä¼šé¸æŠ", 
            options=available_committees,
            default=available_committees
        )
    else:
        committees = []
    
    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ•ã‚£ãƒ«ã‚¿
    keyword_input = st.text_input(
        "ğŸ” ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢", 
        value="",
        placeholder="ä¾‹: ç¨åˆ¶ æ¶ˆè²»ç¨ï¼ˆã‚¹ãƒšãƒ¼ã‚¹åŒºåˆ‡ã‚Šï¼‰",
        help="ç©ºæ¬„ã®å ´åˆã¯å…¨ä»¶å¯¾è±¡"
    )
    
    st.markdown("---")
    st.markdown("### ğŸ“Š è¡¨ç¤ºè¨­å®š")
    show_debug_info = st.checkbox("ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¡¨ç¤º", value=False)
    
    # ã‚°ãƒ©ãƒ•è¡¨ç¤ºã‚ªãƒ—ã‚·ãƒ§ãƒ³
    st.markdown("### ğŸ¨ ã‚°ãƒ©ãƒ•ã‚ªãƒ—ã‚·ãƒ§ãƒ³")
    chart_height = st.slider("ãƒãƒ£ãƒ¼ãƒˆé«˜ã•", min_value=300, max_value=800, value=500, step=50)
    use_horizontal_layout = st.checkbox("é•·ã„ãƒ©ãƒ™ãƒ«ã¯æ¨ªæ£’ã‚°ãƒ©ãƒ•ã§è¡¨ç¤º", value=True)
    max_items_display = st.slider("æœ€å¤§è¡¨ç¤ºé …ç›®æ•°", min_value=10, max_value=50, value=20, step=5)

# =========================
# ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
# =========================
filtered_df = speeches.copy()

# æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿é©ç”¨
if date_range and len(date_range) == 2:
    filtered_df = filtered_df[
        (filtered_df["date"] >= pd.to_datetime(date_range[0])) & 
        (filtered_df["date"] <= pd.to_datetime(date_range[1]))
    ]

# é™¢ãƒ•ã‚£ãƒ«ã‚¿é©ç”¨
if houses:
    filtered_df = filtered_df[filtered_df["house"].isin(houses)]

# å§”å“¡ä¼šãƒ•ã‚£ãƒ«ã‚¿é©ç”¨
if committees:
    filtered_df = filtered_df[filtered_df["committee"].isin(committees)]

# ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ•ã‚£ãƒ«ã‚¿é©ç”¨
if keyword_input.strip():
    keywords = [k.strip() for k in keyword_input.split() if k.strip()]
    pattern = "|".join(map(re.escape, keywords))
    filtered_df = filtered_df[
        filtered_df["speech"].fillna("").str.contains(pattern, regex=True, case=False)
    ]

# =========================
# ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨ç¤º
# =========================
col1, col2, col3, col4 = st.columns(4)

with col1:
    st.metric("ğŸ“ ç·ç™ºè¨€æ•°", f"{len(filtered_df):,}ä»¶")

with col2:
    if not filtered_df.empty:
        unique_speakers = filtered_df["speaker"].nunique()
        st.metric("ğŸ‘¥ ç™ºè¨€è€…æ•°", f"{unique_speakers:,}äºº")
    else:
        st.metric("ğŸ‘¥ ç™ºè¨€è€…æ•°", "0äºº")

with col3:
    if not filtered_df.empty:
        total_chars = filtered_df["char_count"].sum()
        st.metric("ğŸ“Š ç·æ–‡å­—æ•°", f"{total_chars:,}æ–‡å­—")
    else:
        st.metric("ğŸ“Š ç·æ–‡å­—æ•°", "0æ–‡å­—")

with col4:
    if not filtered_df.empty:
        unique_parties = filtered_df["party"].nunique()
        st.metric("ğŸ¢ æ”¿å…šæ•°", f"{unique_parties:,}")
    else:
        st.metric("ğŸ¢ æ”¿å…šæ•°", "0")

# ãƒ‡ãƒ¼ã‚¿ãŒç©ºã®å ´åˆã®å‡¦ç†
if filtered_df.empty:
    st.warning("âš ï¸ é¸æŠã•ã‚ŒãŸæ¡ä»¶ã«è©²å½“ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ãƒ•ã‚£ãƒ«ã‚¿æ¡ä»¶ã‚’è¦‹ç›´ã—ã¦ãã ã•ã„ã€‚")
    st.stop()

st.markdown("---")

# =========================
# ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æã‚»ã‚¯ã‚·ãƒ§ãƒ³
# =========================
st.header("ğŸ”¤ è­°è«–ã•ã‚Œã¦ã„ã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰")

# ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º
with st.spinner("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’åˆ†æä¸­..."):
    all_keywords = []
    for speech in filtered_df['speech'].fillna(''):
        all_keywords.extend(extract_keywords(speech))
    
    # é »å‡ºã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰Top30
    keyword_counter = collections.Counter(all_keywords)
    top_keywords = pd.DataFrame(
        keyword_counter.most_common(30), 
        columns=['term', 'count']
    )

if len(top_keywords) > 0:
    # 2åˆ—ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.subheader("ğŸ“ˆ é »å‡ºã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ Top30")
        keyword_chart = alt.Chart(top_keywords.head(20)).mark_bar().encode(
            x=alt.X('count:Q', title='å‡ºç¾å›æ•°'),
            y=alt.Y('term:N', sort='-x', title='ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰'),
            color=alt.Color('count:Q', scale=alt.Scale(scheme='blues')),
            tooltip=['term:N', 'count:Q']
        ).properties(
            height=500
        )
        st.altair_chart(keyword_chart, use_container_width=True)
    
    with col2:
        st.subheader("ğŸ¯ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰è©³ç´°")
        if len(top_keywords) > 0:
            selected_term = st.selectbox(
                "è©³ç´°ã‚’è¦‹ã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’é¸æŠ",
                options=top_keywords['term'].head(10).tolist(),
                index=0
            )
            
            # é¸æŠã•ã‚ŒãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ä½¿ç”¨ä¾‹
            examples = filtered_df[
                filtered_df['speech'].fillna('').str.contains(
                    re.escape(selected_term), regex=True
                )
            ].sort_values('date', ascending=False)
            
            st.markdown(f"**ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã€Œ{selected_term}ã€ã®ä½¿ç”¨ä¾‹:**")
            for idx, row in examples.head(3).iterrows():
                # ç™ºè¨€ã®ä¸€éƒ¨ã‚’æŠœç²‹
                speech_text = str(row['speech'])
                if len(speech_text) > 150:
                    speech_text = speech_text[:150] + "..."
                
                st.markdown(f"""
                **{row['speaker']}** ({row['party']}) - {row['date'].strftime('%Y-%m-%d')}  
                "{speech_text}"
                """)
    
    # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ï¼ˆæ”¿å…šÃ—ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼‰
    st.subheader("ğŸ”¥ æ”¿å…šÃ—ä¸»è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—")
    
    heatmap_data = create_heatmap_data(filtered_df, top_keywords, top_n=15)
    
    if len(heatmap_data) > 0:
        if show_debug_info:
            with st.expander("ğŸ› ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ— ãƒ‡ãƒãƒƒã‚°æƒ…å ±"):
                st.write(f"ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ãƒ‡ãƒ¼ã‚¿è¡Œæ•°: {len(heatmap_data)}")
                st.write(f"ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•°: {heatmap_data['term'].nunique()}")
                st.write(f"æ”¿å…šæ•°: {heatmap_data['party'].nunique()}")
                st.dataframe(heatmap_data.head(10))
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¨æ”¿å…šã®é †åºã‚’æ±ºå®š
        term_order = (heatmap_data.groupby('term')['count'].sum()
                     .sort_values(ascending=False).index.tolist())
        party_order = (heatmap_data.groupby('party')['count'].sum()
                      .sort_values(ascending=False).index.tolist())
        
        # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã®ã‚µã‚¤ã‚ºã¨ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã‚’æ”¹å–„
        max_term_length = max([len(term) for term in term_order]) if term_order else 0
        max_party_length = max([len(party) for party in party_order]) if party_order else 0
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•°ãŒå¤šã„å ´åˆã¯è¡¨ç¤ºæ•°ã‚’åˆ¶é™
        if len(term_order) > 20:
            term_order = term_order[:20]
            heatmap_data = heatmap_data[heatmap_data['term'].isin(term_order)]
            st.info("âš ï¸ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•°ãŒå¤šã„ãŸã‚ã€ä¸Šä½20å€‹ã®ã¿è¡¨ç¤ºã—ã¦ã„ã¾ã™")
        
        heatmap_chart = alt.Chart(heatmap_data).mark_rect(stroke='white', strokeWidth=1).encode(
            x=alt.X('term:O', 
                   title='ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰',
                   sort=term_order,
                   axis=alt.Axis(
                       labelAngle=-45 if max_term_length > 3 else 0,
                       labelLimit=0,
                       labelFontSize=9,
                       titleFontSize=12
                   )),
            y=alt.Y('party:O', 
                   title='æ”¿å…š',
                   sort=party_order,
                   axis=alt.Axis(
                       labelLimit=0,
                       labelFontSize=9,
                       titleFontSize=12
                   )),
            color=alt.Color('count:Q', 
                          title='ç™ºè¨€é »åº¦',
                          scale=alt.Scale(
                              type='sqrt',
                              range=['#f7f7f7', '#2166ac']
                          )),
            tooltip=[
                alt.Tooltip('party:N', title='æ”¿å…š'),
                alt.Tooltip('term:N', title='ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰'),
                alt.Tooltip('count:Q', title='é »åº¦')
            ]
        ).properties(
            width=max(600, len(term_order) * 40),
            height=max(300, len(party_order) * 35)
        ).resolve_scale(
            color='independent'
        )
        
        st.altair_chart(heatmap_chart, use_container_width=True)
    else:
        st.info("â„¹ï¸ ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ç”¨ã®ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚")

else:
    st.info("â„¹ï¸ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒæŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ãƒ‡ãƒ¼ã‚¿ã®å†…å®¹ã‚„ãƒ•ã‚£ãƒ«ã‚¿æ¡ä»¶ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

st.markdown("---")

# =========================
# ç™ºè¨€é‡åˆ†æã‚»ã‚¯ã‚·ãƒ§ãƒ³
# =========================
st.header("ğŸ“Š ç™ºè¨€é‡åˆ†æ")

col1, col2 = st.columns(2)

with col1:
    st.subheader("ğŸ‘¤ è­°å“¡åˆ¥ç™ºè¨€é‡ Top20")
    if not filtered_df.empty:
        speaker_ranking = (
            filtered_df.groupby(["speaker", "party"], as_index=False)["char_count"]
            .sum()
            .sort_values("char_count", ascending=False)
            .head(20)
        )
        
        speaker_chart = alt.Chart(speaker_ranking).mark_bar().encode(
            x=alt.X("char_count:Q", title="ç™ºè¨€æ–‡å­—æ•°"),
            y=alt.Y("speaker:N", sort='-x', title="è­°å“¡å"),
            color=alt.Color("party:N", title="æ”¿å…š", scale=alt.Scale(scheme='category20')),
            tooltip=["speaker:N", "party:N", "char_count:Q"]
        ).properties(height=500)
        
        st.altair_chart(speaker_chart, use_container_width=True)
    else:
        st.info("ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")

with col2:
    st.subheader("ğŸ¢ æ”¿å…šåˆ¥ç™ºè¨€æ•°")
    if not filtered_df.empty:
        party_stats = (
            filtered_df.groupby("party", as_index=False)
            .agg({
                "speech": "count",
                "char_count": "sum"
            })
            .rename(columns={"speech": "speech_count"})
            .sort_values("speech_count", ascending=False)
        )
        
        # æ”¿å…šåãŒé•·ã„å ´åˆã¯æ¨ªæ£’ã‚°ãƒ©ãƒ•ã«å¤‰æ›´
        if len(party_stats) > 8 or party_stats['party'].str.len().max() > 6:
            party_chart = alt.Chart(party_stats).mark_bar().encode(
                x=alt.X("speech_count:Q", title="ç™ºè¨€æ•°"),
                y=alt.Y("party:O", title="æ”¿å…š", sort="-x", 
                       axis=alt.Axis(labelLimit=200, labelFontSize=10)),
                color=alt.Color("speech_count:Q", scale=alt.Scale(scheme='viridis')),
                tooltip=["party:N", "speech_count:Q", "char_count:Q"]
            ).properties(height=max(400, len(party_stats) * 30))
        else:
            party_chart = alt.Chart(party_stats).mark_bar().encode(
                x=alt.X("party:N", title="æ”¿å…š", 
                       axis=alt.Axis(labelAngle=-45, labelLimit=0, labelFontSize=10)),
                y=alt.Y("speech_count:Q", title="ç™ºè¨€æ•°"),
                color=alt.Color("speech_count:Q", scale=alt.Scale(scheme='viridis')),
                tooltip=["party:N", "speech_count:Q", "char_count:Q"]
            ).properties(height=500)
        
        st.altair_chart(party_chart, use_container_width=True)
    else:
        st.info("ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")

# æ™‚ç³»åˆ—åˆ†æ
st.subheader("ğŸ“ˆ ç™ºè¨€æ•°ã®æ¨ç§»ï¼ˆæ—¥åˆ¥ï¼‰")
if not filtered_df.empty and not filtered_df["date"].isna().all():
    daily_stats = (
        filtered_df.groupby("date", as_index=False)
        .agg({
            "speech": "count",
            "char_count": "sum"
        })
        .rename(columns={"speech": "speech_count"})
    )
    
    timeline_chart = alt.Chart(daily_stats).mark_line(point=True).encode(
        x=alt.X("date:T", title="æ—¥ä»˜"),
        y=alt.Y("speech_count:Q", title="ç™ºè¨€æ•°"),
        tooltip=["date:T", "speech_count:Q", "char_count:Q"]
    ).properties(height=300)
    
    st.altair_chart(timeline_chart, use_container_width=True)
else:
    st.info("â„¹ï¸ æ—¥ä»˜ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã‚‹ãŸã‚æ™‚ç³»åˆ—åˆ†æã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")

st.markdown("---")

# =========================
# æœ€æ–°ç™ºè¨€ã‚»ã‚¯ã‚·ãƒ§ãƒ³
# =========================
st.header("ğŸ“° æœ€æ–°ã®ç™ºè¨€")

if not filtered_df.empty:
    latest_speeches = (
        filtered_df.sort_values("date", ascending=False)
        .head(20)
        [["date", "house", "committee", "speaker", "party", "speech"]]
        .copy()
    )
    
    # ç™ºè¨€ã‚’é©åˆ‡ãªé•·ã•ã«åˆ‡ã‚Šè©°ã‚
    latest_speeches["speech"] = (
        latest_speeches["speech"]
        .fillna("")
        .astype(str)
        .apply(lambda x: (x[:200] + "...") if len(x) > 200 else x)
    )
    
    # æ—¥ä»˜ã‚’èª­ã¿ã‚„ã™ã„å½¢å¼ã«å¤‰æ›
    latest_speeches["date"] = latest_speeches["date"].dt.strftime("%Y-%m-%d")
    
    st.dataframe(
        latest_speeches, 
        use_container_width=True,
        column_config={
            "date": "æ—¥ä»˜",
            "house": "é™¢",
            "committee": "å§”å“¡ä¼š",
            "speaker": "ç™ºè¨€è€…",
            "party": "æ”¿å…š",
            "speech": "ç™ºè¨€å†…å®¹"
        }
    )
else:
    st.info("è¡¨ç¤ºã™ã‚‹ç™ºè¨€ãŒã‚ã‚Šã¾ã›ã‚“")

# =========================
# ãƒ•ãƒƒã‚¿ãƒ¼
# =========================
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: #666; padding: 2rem;'>
    <p>ğŸ“Š <strong>å›½ä¼šãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰</strong> | ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹: å›½ä¼šä¼šè­°éŒ²æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ  API</p>
    <p>ğŸ”§ ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ç‰ˆ | ã‚ˆã‚Šè©³ç´°ãªåˆ†ææ©Ÿèƒ½ã¯éšæ™‚è¿½åŠ äºˆå®š</p>
</div>
""", unsafe_allow_html=True)